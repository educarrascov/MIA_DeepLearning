{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvB49Rn1Bh_3"
   },
   "source": [
    "# Clase extra: Autoencoders\n",
    "\n",
    "\n",
    "## 1. Autoenconder simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97QSRQI0BvBT"
   },
   "source": [
    "Cargarmos las librerías para ejecutar los experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6t2j3QwUBuXC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6xUQI4UBw89"
   },
   "source": [
    "Definimos una función para transformar un vector de entrada en una imagen. (Esto por que la base de datos MNIST no contiene imágenes sino vectores de imágenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gg25QofNBv8v"
   },
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDfdGIP2CToa"
   },
   "source": [
    "Implementamos una __transformer__ para normalizar la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RPXndIF3CUDx"
   },
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FxMZfBSCg_W"
   },
   "source": [
    "Cargamos la base de datos MNIST y construimos un _dataloader_ para cargar en _batch_ los ejemplos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422,
     "referenced_widgets": [
      "7b3298615de44d2793d98244807e5927",
      "27bbeaa25d184943b58ded52f4c6a0c5",
      "9b6712be5b394ff9a59e1f0fa45e16bf",
      "353bdb8ed6464531b4c9ec610b9e51f9",
      "928cb9853b3548ad9493846a9c206b05",
      "eccdf99e00f3475ca5eb7a658fd75b75",
      "7ea6a75d932e49af8e80ea6ae850a443",
      "60854e2a09864992b2facdcf39ab15fa",
      "122cad50a9724842b56ef282ee793be0",
      "964912c6badf4846b05dc0ce6fc378e7",
      "932a7cc2512c400db4fc72061cd734f9",
      "b2ec658f2eb04f7eba106ba47c9cc1e7",
      "2066b5e2bc1941408ca643d008a28249",
      "cb4375f340334f85b02c655b5eb4eded",
      "133a1f780d3b47649465f10d30a882b0",
      "c5f2505c07164fee9312a47d767d2396",
      "946fcdbe0aba449d8424f1a780eadcf4",
      "8e0db1058b854d2ca3d3721aea3d6583",
      "813ee1cc0c3348f0af7428def39db84e",
      "750aa3eb9fa04b9884d809a33f34c6dc",
      "b0c777bec32e4b4c83742b1387254308",
      "8a2e41ab049d4deb913dc852a43a409f",
      "9484eb460dd54f2b96f7bade1e154155",
      "d69cc4571ebe457f9e2400cdb03a01b3",
      "c5cc325fae624fb4ac20930c9997869e",
      "6b4747bd76954ee89a776d479e50fcdd",
      "10886c914f5340ad8ef3b0485d195ba0",
      "61347a761bd64447ae841aaaf78909dc",
      "689ab72ad8294012850a1cb66b45701a",
      "c6cf065fca0e4a52b3cf8f3d60b5c353",
      "ac6b56e64e284cce85b5c1898cc9ee93",
      "ccccd804cbed4206ad3e976d99943339",
      "dcdcd7dfe10c449aa6e4121f7d64b81a",
      "4a92ceaa78594e99b8c7411cf8db3cd1",
      "f2f4f6c4118641118c9bb06070f599d9",
      "cc1f0d0dc0f74046a9407dad4d0b2e65",
      "1009595091fc40439394fe260b4e4f70",
      "2b0f421b2d62485ca780b11a6925eb8d",
      "240595ba744a4d288b5126ad84d0be4e",
      "35806adca05c470890d9a75269872d6a",
      "2a1607cb4afc4f08bebfb05a3bdedf09",
      "4cf9bb165ec64223af21f113b6c736cf",
      "37964ff3443448ac8cdeb96e26984076",
      "030fcc5947304c459dc69321853c6261"
     ]
    },
    "id": "M_hN4Hl1ChJz",
    "outputId": "d24a34b6-9096-4299-83cc-a198140ea816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3298615de44d2793d98244807e5927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ec658f2eb04f7eba106ba47c9cc1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9484eb460dd54f2b96f7bade1e154155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a92ceaa78594e99b8c7411cf8db3cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "dataset = MNIST('./data', download=True, transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxI5mEZaC2aq"
   },
   "source": [
    "Definimos el modelo de autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2EDq-mUpC2_m"
   },
   "outputs": [],
   "source": [
    "class AutoencoderSimple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoencoderSimple, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(64, 12), \n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(12, 3))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXjdyV5tDCEo"
   },
   "source": [
    "### Entrenamiento\n",
    "\n",
    "Definimos cuales son los hiperparámetros para el algoritmo de optimización definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Dsy1SIh8DCfE"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fl1TI9aRDUU8"
   },
   "source": [
    "Definimos el algoritmo de optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "A6KZHat_DUwV"
   },
   "outputs": [],
   "source": [
    "model = AutoencoderSimple().cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tgPL6JfDkYJ"
   },
   "source": [
    "Entrenamiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgs5xywADlMl",
    "outputId": "e67830bd-f152-4724-fa77-b77ba9b17e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100] loss: 0.18970146775245667 size: torch.Size([96, 784])\n",
      "epoch [2/100] loss: 0.18039152026176453 size: torch.Size([96, 784])\n",
      "epoch [3/100] loss: 0.1558837592601776 size: torch.Size([96, 784])\n",
      "epoch [4/100] loss: 0.16556891798973083 size: torch.Size([96, 784])\n",
      "epoch [5/100] loss: 0.14936776459217072 size: torch.Size([96, 784])\n",
      "epoch [6/100] loss: 0.14701464772224426 size: torch.Size([96, 784])\n",
      "epoch [7/100] loss: 0.12891629338264465 size: torch.Size([96, 784])\n",
      "epoch [8/100] loss: 0.14842307567596436 size: torch.Size([96, 784])\n",
      "epoch [9/100] loss: 0.1262117177248001 size: torch.Size([96, 784])\n",
      "epoch [10/100] loss: 0.1362428218126297 size: torch.Size([96, 784])\n",
      "epoch [11/100] loss: 0.1277216672897339 size: torch.Size([96, 784])\n",
      "epoch [12/100] loss: 0.1356513351202011 size: torch.Size([96, 784])\n",
      "epoch [13/100] loss: 0.12361467629671097 size: torch.Size([96, 784])\n",
      "epoch [14/100] loss: 0.14186862111091614 size: torch.Size([96, 784])\n",
      "epoch [15/100] loss: 0.12808160483837128 size: torch.Size([96, 784])\n",
      "epoch [16/100] loss: 0.142474964261055 size: torch.Size([96, 784])\n",
      "epoch [17/100] loss: 0.13336706161499023 size: torch.Size([96, 784])\n",
      "epoch [18/100] loss: 0.1221933513879776 size: torch.Size([96, 784])\n",
      "epoch [19/100] loss: 0.1351807713508606 size: torch.Size([96, 784])\n",
      "epoch [20/100] loss: 0.12693731486797333 size: torch.Size([96, 784])\n",
      "epoch [21/100] loss: 0.13664619624614716 size: torch.Size([96, 784])\n",
      "epoch [22/100] loss: 0.12311165779829025 size: torch.Size([96, 784])\n",
      "epoch [23/100] loss: 0.12059435993432999 size: torch.Size([96, 784])\n",
      "epoch [24/100] loss: 0.11738002300262451 size: torch.Size([96, 784])\n",
      "epoch [25/100] loss: 0.13389135897159576 size: torch.Size([96, 784])\n",
      "epoch [26/100] loss: 0.12277622520923615 size: torch.Size([96, 784])\n",
      "epoch [27/100] loss: 0.12218882143497467 size: torch.Size([96, 784])\n",
      "epoch [28/100] loss: 0.12320980429649353 size: torch.Size([96, 784])\n",
      "epoch [29/100] loss: 0.129853293299675 size: torch.Size([96, 784])\n",
      "epoch [30/100] loss: 0.1466520130634308 size: torch.Size([96, 784])\n",
      "epoch [31/100] loss: 0.12151480466127396 size: torch.Size([96, 784])\n",
      "epoch [32/100] loss: 0.12664876878261566 size: torch.Size([96, 784])\n",
      "epoch [33/100] loss: 0.11693823337554932 size: torch.Size([96, 784])\n",
      "epoch [34/100] loss: 0.1296454221010208 size: torch.Size([96, 784])\n",
      "epoch [35/100] loss: 0.13529743254184723 size: torch.Size([96, 784])\n",
      "epoch [36/100] loss: 0.12803436815738678 size: torch.Size([96, 784])\n",
      "epoch [37/100] loss: 0.13597780466079712 size: torch.Size([96, 784])\n",
      "epoch [38/100] loss: 0.12951131165027618 size: torch.Size([96, 784])\n",
      "epoch [39/100] loss: 0.12152432650327682 size: torch.Size([96, 784])\n",
      "epoch [40/100] loss: 0.12041141092777252 size: torch.Size([96, 784])\n",
      "epoch [41/100] loss: 0.1345023363828659 size: torch.Size([96, 784])\n",
      "epoch [42/100] loss: 0.12166431546211243 size: torch.Size([96, 784])\n",
      "epoch [43/100] loss: 0.12479616701602936 size: torch.Size([96, 784])\n",
      "epoch [44/100] loss: 0.13895376026630402 size: torch.Size([96, 784])\n",
      "epoch [45/100] loss: 0.1343732327222824 size: torch.Size([96, 784])\n",
      "epoch [46/100] loss: 0.12322398275136948 size: torch.Size([96, 784])\n",
      "epoch [47/100] loss: 0.1251191794872284 size: torch.Size([96, 784])\n",
      "epoch [48/100] loss: 0.12052202224731445 size: torch.Size([96, 784])\n",
      "epoch [49/100] loss: 0.12513907253742218 size: torch.Size([96, 784])\n",
      "epoch [50/100] loss: 0.12180814892053604 size: torch.Size([96, 784])\n",
      "epoch [51/100] loss: 0.12484517693519592 size: torch.Size([96, 784])\n",
      "epoch [52/100] loss: 0.11877594143152237 size: torch.Size([96, 784])\n",
      "epoch [53/100] loss: 0.12506738305091858 size: torch.Size([96, 784])\n",
      "epoch [54/100] loss: 0.12877239286899567 size: torch.Size([96, 784])\n",
      "epoch [55/100] loss: 0.12441283464431763 size: torch.Size([96, 784])\n",
      "epoch [56/100] loss: 0.1305384486913681 size: torch.Size([96, 784])\n",
      "epoch [57/100] loss: 0.12437355518341064 size: torch.Size([96, 784])\n",
      "epoch [58/100] loss: 0.1233094111084938 size: torch.Size([96, 784])\n",
      "epoch [59/100] loss: 0.1271907389163971 size: torch.Size([96, 784])\n",
      "epoch [60/100] loss: 0.12370381504297256 size: torch.Size([96, 784])\n",
      "epoch [61/100] loss: 0.12957115471363068 size: torch.Size([96, 784])\n",
      "epoch [62/100] loss: 0.12979069352149963 size: torch.Size([96, 784])\n",
      "epoch [63/100] loss: 0.14313751459121704 size: torch.Size([96, 784])\n",
      "epoch [64/100] loss: 0.13054536283016205 size: torch.Size([96, 784])\n",
      "epoch [65/100] loss: 0.1180504783987999 size: torch.Size([96, 784])\n",
      "epoch [66/100] loss: 0.1227693110704422 size: torch.Size([96, 784])\n",
      "epoch [67/100] loss: 0.14098133146762848 size: torch.Size([96, 784])\n",
      "epoch [68/100] loss: 0.12329403311014175 size: torch.Size([96, 784])\n",
      "epoch [69/100] loss: 0.13084276020526886 size: torch.Size([96, 784])\n",
      "epoch [70/100] loss: 0.11916234344244003 size: torch.Size([96, 784])\n",
      "epoch [71/100] loss: 0.12648658454418182 size: torch.Size([96, 784])\n",
      "epoch [72/100] loss: 0.12706340849399567 size: torch.Size([96, 784])\n",
      "epoch [73/100] loss: 0.11838893592357635 size: torch.Size([96, 784])\n",
      "epoch [74/100] loss: 0.12272202968597412 size: torch.Size([96, 784])\n",
      "epoch [75/100] loss: 0.1204361543059349 size: torch.Size([96, 784])\n",
      "epoch [76/100] loss: 0.12264378368854523 size: torch.Size([96, 784])\n",
      "epoch [77/100] loss: 0.11473117023706436 size: torch.Size([96, 784])\n",
      "epoch [78/100] loss: 0.11799111217260361 size: torch.Size([96, 784])\n",
      "epoch [79/100] loss: 0.11927314847707748 size: torch.Size([96, 784])\n",
      "epoch [80/100] loss: 0.12499963492155075 size: torch.Size([96, 784])\n",
      "epoch [81/100] loss: 0.11904655396938324 size: torch.Size([96, 784])\n",
      "epoch [82/100] loss: 0.11623626202344894 size: torch.Size([96, 784])\n",
      "epoch [83/100] loss: 0.1331377476453781 size: torch.Size([96, 784])\n",
      "epoch [84/100] loss: 0.1285964846611023 size: torch.Size([96, 784])\n",
      "epoch [85/100] loss: 0.12134911119937897 size: torch.Size([96, 784])\n",
      "epoch [86/100] loss: 0.12865491211414337 size: torch.Size([96, 784])\n",
      "epoch [87/100] loss: 0.1187060996890068 size: torch.Size([96, 784])\n",
      "epoch [88/100] loss: 0.12181180715560913 size: torch.Size([96, 784])\n",
      "epoch [89/100] loss: 0.10811116546392441 size: torch.Size([96, 784])\n",
      "epoch [90/100] loss: 0.12408538162708282 size: torch.Size([96, 784])\n",
      "epoch [91/100] loss: 0.10505573451519012 size: torch.Size([96, 784])\n",
      "epoch [92/100] loss: 0.1112058162689209 size: torch.Size([96, 784])\n",
      "epoch [93/100] loss: 0.12207426875829697 size: torch.Size([96, 784])\n",
      "epoch [94/100] loss: 0.12360361218452454 size: torch.Size([96, 784])\n",
      "epoch [95/100] loss: 0.12169483304023743 size: torch.Size([96, 784])\n",
      "epoch [96/100] loss: 0.12680910527706146 size: torch.Size([96, 784])\n",
      "epoch [97/100] loss: 0.12402079999446869 size: torch.Size([96, 784])\n",
      "epoch [98/100] loss: 0.12264838069677353 size: torch.Size([96, 784])\n",
      "epoch [99/100] loss: 0.12487992644309998 size: torch.Size([96, 784])\n",
      "epoch [100/100] loss: 0.11627010256052017 size: torch.Size([96, 784])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img).cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print(f'epoch [{epoch+1}/{num_epochs}] loss: {loss.item()} size: {output.shape}')\n",
    "    if epoch % 10 == 0:\n",
    "        pic_out = to_img(output.cpu().data)\n",
    "        pic_inp = to_img(img.cpu().data)\n",
    "        save_image(pic_inp, f'/content/image-inp_{epoch}.png')\n",
    "        save_image(pic_out, f'/content/image-out_{epoch}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDXsc2jMFAB3"
   },
   "source": [
    "Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ywTSKHMFAXQ"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "AUTOENCODERSimple.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
